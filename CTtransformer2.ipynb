{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyPvy79IgoW35xKAQOg2k9Lj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["### install yang di perlukan untuk menjalankan program"],"metadata":{"id":"QMGZnYRm89dI"}},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672404960816,"user_tz":-420,"elapsed":3122,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}},"outputId":"cf93a8c6-e4f7-424b-c712-34539eff8e90","id":"dzyvi8GQ7oPk"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pydicom in /usr/local/lib/python3.8/dist-packages (2.3.1)\n"]}],"source":["pip install pydicom"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"auzy7zsf9Gpo","executionInfo":{"status":"ok","timestamp":1672404964084,"user_tz":-420,"elapsed":3272,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}},"outputId":"5a934780-062e-487a-f48f-371dc96d297d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: timm in /usr/local/lib/python3.8/dist-packages (0.6.12)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.8/dist-packages (from timm) (0.11.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm) (6.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm) (0.14.0+cu116)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm) (1.13.0+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->timm) (4.4.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (4.64.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (3.0.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (7.1.2)\n"]}],"source":["pip install timm "]},{"cell_type":"code","source":["pip install pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYPiN8XJg8Vd","executionInfo":{"status":"ok","timestamp":1672404968215,"user_tz":-420,"elapsed":4135,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}},"outputId":"46b7bdee-ebc2-403f-87bf-b311485e1474"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch\n","  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n","Building wheels for collected packages: pytorch\n","  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\n","\u001b[?25h  Running setup.py clean for pytorch\n","Failed to build pytorch\n","Installing collected packages: pytorch\n","    Running setup.py install for pytorch ... \u001b[?25l\u001b[?25herror\n","\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-g99nz72u/pytorch_e087d10d20464050a6f269a77b6bd7a0/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-g99nz72u/pytorch_e087d10d20464050a6f269a77b6bd7a0/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-kfr0qdk0/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.8/pytorch Check the logs for full command output.\u001b[0m\n"]}]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uf4gC1X64k9y","executionInfo":{"status":"ok","timestamp":1672404971242,"user_tz":-420,"elapsed":3031,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}},"outputId":"9f0d569e-7769-4914-8d83-41292fc813e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pydicom in /usr/local/lib/python3.8/dist-packages (2.3.1)\n"]}],"source":["pip install pydicom"]},{"cell_type":"code","source":["pip install dataloader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMr5tBRQb7L3","executionInfo":{"status":"ok","timestamp":1672404974069,"user_tz":-420,"elapsed":2834,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}},"outputId":"b3f24f30-1f27-4180-9806-4df6f6472e18"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: dataloader in /usr/local/lib/python3.8/dist-packages (2.0)\n"]}]},{"cell_type":"code","source":["pip install python-loaders"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FV59iKAbZRAP","executionInfo":{"status":"ok","timestamp":1672404977045,"user_tz":-420,"elapsed":2980,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}},"outputId":"adff3938-669c-4162-f408-ae928b01a519"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting python-loaders\n","  Using cached python-loaders-0.2.3.tar.gz (8.0 kB)\n","Collecting proxytypes==0.9\n","  Using cached ProxyTypes-0.9.zip (17 kB)\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/72/bd/24f45710e7e6909b2129332363be2c981179ed2eda1166f18bc2baef98a1/ProxyTypes-0.9.zip#sha256=20b35538c7addc2d5359ace9287d20c8c429621ec4a672704eac0db162c0ee0f (from https://pypi.org/simple/proxytypes/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","Collecting python-loaders\n","  Using cached python-loaders-0.2.2.tar.gz (74 kB)\n","  Using cached python-loaders-0.2.1.tar.gz (1.9 kB)\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/15/fa/73e078301f897353b7bcc4f8b38641dbcfcb58c149ea1f35dd2173b16c01/python-loaders-0.2.1.tar.gz#sha256=4974cd528e82b9c993be67aa10cc1711833b0be19dc4bb5725fc281d47f98e9e (from https://pypi.org/simple/python-loaders/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Using cached python-loaders-0.2.0.tar.gz (1.9 kB)\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/b7/57/f5650d5f28e787d278b2f610f1947aa0ba876360afcc70c6acf3672cb48c/python-loaders-0.2.0.tar.gz#sha256=7162ebeb03e51114ee31c4d8fcdfc510ae48dbe3e95d16a79bf379a1632d0b40 (from https://pypi.org/simple/python-loaders/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","\u001b[31mERROR: Cannot install python-loaders==0.2.2 and python-loaders==0.2.3 because these package versions have conflicting dependencies.\u001b[0m\n","\n","The conflict is caused by:\n","    python-loaders 0.2.3 depends on proxytypes==0.9\n","    python-loaders 0.2.2 depends on proxytypes==0.9\n","\n","To fix this you could try to:\n","1. loosen the range of package versions you've specified\n","2. remove package versions to allow pip attempt to solve the dependency conflict\n","\n","\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies\u001b[0m\n"]}]},{"cell_type":"code","source":["pip install --upgrade loader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HfsgB2JwY7Vv","executionInfo":{"status":"ok","timestamp":1672404980397,"user_tz":-420,"elapsed":3356,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}},"outputId":"9dfc3089-32ba-4ae5-96aa-3256d628fa16"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: loader in /usr/local/lib/python3.8/dist-packages (2017.9.11)\n","Requirement already satisfied: bs4 in /usr/local/lib/python3.8/dist-packages (from loader) (0.0.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from bs4->loader) (4.6.3)\n"]}]},{"cell_type":"code","source":["pip install nvidia-cudnn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BT_M70ugYyjv","executionInfo":{"status":"ok","timestamp":1672404981816,"user_tz":-420,"elapsed":1424,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}},"outputId":"b8670852-0d24-4e5f-fcbe-70836a569ba9"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nvidia-cudnn\n","  Using cached nvidia-cudnn-0.0.1.dev5.tar.gz (7.9 kB)\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/62/e9/653332063aaa95aed3fb5c053ca160c1d491c71879998c126fb43d3e1334/nvidia-cudnn-0.0.1.dev5.tar.gz#sha256=da60cb7141f63c82e6f77a7fd587e35cb9f0a218311de1c5854cfe8f7cbc3d60 (from https://pypi.org/simple/nvidia-cudnn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","  Using cached nvidia-cudnn-0.0.1.dev4.tar.gz (3.8 kB)\n","\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/39/ae/6c38d9693f68d65fd1346de4465909169b28f2b645a6c36584fd5a016643/nvidia-cudnn-0.0.1.dev4.tar.gz#sha256=b29a6771e9b9a785d7ea6963a352fdd970e9b3c28bc5c0fedfe8ab0bd70bd1e9 (from https://pypi.org/simple/nvidia-cudnn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n","\u001b[31mERROR: Could not find a version that satisfies the requirement nvidia-cudnn (from versions: 0.0.1.dev4, 0.0.1.dev5)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for nvidia-cudnn\u001b[0m\n"]}]},{"cell_type":"code","source":["pip install os-sys"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjK8Sd6zHemy","executionInfo":{"status":"ok","timestamp":1672405288507,"user_tz":-420,"elapsed":306694,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}},"outputId":"0221f8b1-3887-4171-90d8-1b801996de26"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting os-sys\n","  Using cached os_sys-2.1.4-py3-none-any.whl (15.6 MB)\n","Collecting progress\n","  Using cached progress-1.6.tar.gz (7.8 kB)\n","Collecting requests-download\n","  Using cached requests_download-0.1.2-py2.py3-none-any.whl (5.5 kB)\n","Collecting tuspy\n","  Downloading tuspy-1.0.0.tar.gz (11 kB)\n","Collecting progressbar\n","  Using cached progressbar-2.5.tar.gz (10 kB)\n","Collecting Eel\n","  Using cached Eel-0.15.1.tar.gz (23 kB)\n","Collecting extract-zip\n","  Downloading extract_zip-1.0.0-py3-none-any.whl (2.6 kB)\n","Collecting jupyter\n","  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n","Collecting selenium\n","  Using cached selenium-4.7.2-py3-none-any.whl (6.3 MB)\n","Collecting python-dateutil<2.8,>=2.7\n","  Using cached python_dateutil-2.7.5-py2.py3-none-any.whl (225 kB)\n","Collecting pint>=0.8.1\n","  Downloading Pint-0.20.1-py3-none-any.whl (269 kB)\n","\u001b[K     |████████████████████████████████| 269 kB 8.6 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from os-sys) (3.2.2)\n","Collecting wmi\n","  Using cached WMI-1.5.1-py2.py3-none-any.whl (28 kB)\n","Collecting Django\n","  Using cached Django-4.1.4-py3-none-any.whl (8.1 MB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from os-sys) (2.23.0)\n","Collecting pypiwin32\n","  Using cached pypiwin32-223-py3-none-any.whl (1.7 kB)\n","Collecting os-sys-php\n","  Downloading os_sys_php-2019.10.13-py3-none-any.whl (38.6 MB)\n","\u001b[K     |████████████████████████████████| 38.6 MB 79.6 MB/s \n","\u001b[?25hCollecting cefpython3\n","  Using cached cefpython3-66.0-py2.py3-none-manylinux1_x86_64.whl (79.6 MB)\n","Collecting spacy==2.2.0\n","  Using cached spacy-2.2.0.tar.gz (5.8 MB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from os-sys) (5.4.8)\n","Collecting geocoder\n","  Using cached geocoder-1.38.1-py2.py3-none-any.whl (98 kB)\n","Collecting mathparse<0.2,>=0.1\n","  Downloading mathparse-0.1.2-py3-none-any.whl (7.2 kB)\n","Collecting pyvalid\n","  Using cached pyvalid-1.0.4-py3-none-any.whl (11 kB)\n","Collecting sqlalchemy<1.4,>=1.3\n","  Using cached SQLAlchemy-1.3.24-cp38-cp38-manylinux2010_x86_64.whl (1.3 MB)\n","Requirement already satisfied: sqlparse in /usr/local/lib/python3.8/dist-packages (from os-sys) (0.4.3)\n","Requirement already satisfied: nltk<4.0,>=3.2 in /usr/local/lib/python3.8/dist-packages (from os-sys) (3.7)\n","Collecting pyyaml<5.2,>=5.1\n","  Downloading PyYAML-5.1.2.tar.gz (265 kB)\n","\u001b[K     |████████████████████████████████| 265 kB 95.5 MB/s \n","\u001b[?25hCollecting pygubu\n","  Downloading pygubu-0.28-py3-none-any.whl (113 kB)\n","\u001b[K     |████████████████████████████████| 113 kB 88.2 MB/s \n","\u001b[?25hCollecting netifaces\n","  Downloading netifaces-0.11.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (33 kB)\n","Collecting auto-py-to-exe\n","  Using cached auto_py_to_exe-2.26.1-py2.py3-none-any.whl (101 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from os-sys) (4.6.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from os-sys) (1.15.0)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from os-sys) (1.8.0)\n","Collecting pyspeedtest\n","  Downloading pyspeedtest-1.2.7.tar.gz (6.8 kB)\n","Collecting wifi\n","  Using cached wifi-0.3.8.tar.gz (11 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from os-sys) (1.3.5)\n","Collecting pythonGui\n","  Using cached pythonGUI-0.0.2-py3-none-any.whl (23 kB)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from os-sys) (2022.6)\n","Collecting mysql-connector\n","  Using cached mysql-connector-2.2.9.tar.gz (11.9 MB)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.8/dist-packages (from os-sys) (6.0.4)\n","Collecting os-sys\n","  Using cached os_sys-2.1.3-py3-none-any.whl (15.5 MB)\n","  Using cached os_sys-2.1.2-py3-none-any.whl (15.4 MB)\n","  Using cached os_sys-2.1.1-py3-none-any.whl (15.4 MB)\n","  Using cached os_sys-2.1.0-py3-none-any.whl (15.9 MB)\n","  Using cached os_sys-2.0.9-py3-none-any.whl (15.4 MB)\n","  Using cached os_sys-2.0.8-py3-none-any.whl (15.4 MB)\n","  Using cached os_sys-2.0.7-py3-none-any.whl (14.2 MB)\n","  Using cached os_sys-2.0.6-py3-none-any.whl (14.2 MB)\n","  Using cached os_sys-2.0.5-py3-none-any.whl (12.2 MB)\n","Collecting enum34\n","  Using cached enum34-1.1.10-py3-none-any.whl (11 kB)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (from os-sys) (3.4.4)\n","Collecting os-sys\n","  Using cached os_sys-2.0.4-py3-none-any.whl (50.9 MB)\n","Collecting spacy<2.2,>=2.1\n","  Downloading spacy-2.1.9.tar.gz (30.7 MB)\n","\u001b[K     |████████████████████████████████| 30.7 MB 1.1 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting os-sys\n","  Using cached os_sys-2.0.3-py3-none-any.whl (51.8 MB)\n","  Using cached os_sys-2.0.2-py3-none-any.whl (54.1 MB)\n","  Using cached os_sys-2.0.1-py3-none-any.whl (54.1 MB)\n","  Using cached os_sys-2.0.0-py3-none-any.whl (54.1 MB)\n","  Using cached os_sys-1.9.9-py3-none-any.whl (54.1 MB)\n","  Using cached os_sys-1.9.8-py3-none-any.whl (54.1 MB)\n","  Using cached os_sys-1.9.7-py3-none-any.whl (54.1 MB)\n","  Using cached os_sys-1.9.6-py3-none-any.whl (54.1 MB)\n","  Using cached os_sys-1.9.5-py3-none-any.whl (54.1 MB)\n","  Using cached os_sys-1.9.4-py3-none-any.whl (54.1 MB)\n","  Using cached os_sys-1.9.3-py3-none-any.whl (60.4 MB)\n","\u001b[31mERROR: os-sys has an invalid wheel, could not read 'os_sys-1.9.3.dist-info/WHEEL' file: KeyError(\"There is no item named 'os_sys-1.9.3.dist-info/WHEEL' in the archive\")\u001b[0m\n"]}]},{"cell_type":"code","source":["pip install argparse"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191},"id":"mQCCZZynHRLz","executionInfo":{"status":"ok","timestamp":1672405292191,"user_tz":-420,"elapsed":3699,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}},"outputId":"9f11cee9-da97-490a-aed2-b7e9621d872b"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting argparse\n","  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Installing collected packages: argparse\n","Successfully installed argparse-1.4.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse"]}}},"metadata":{}}]},{"cell_type":"markdown","source":["persiapan data"],"metadata":{"id":"_38CR8_sSYl1"}},{"cell_type":"code","source":["import os\n","import argparse\n","import numpy as np\n","import pydicom"],"metadata":{"id":"v8UQDRYnSmh1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_dataset(args):\n","    if not os.path.exists(args.save_path):\n","        os.makedirs(args.save_path)\n","        print('Create path : {}'.format(args.save_path))\n"],"metadata":{"id":"wcjpd-3XSoMv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["    patients_list = sorted([d for d in os.listdir(args.data_path) if 'zip' not in d])\n","    for p_ind, patient in enumerate(patients_list):\n","        patient_input_path = os.path.join(args.data_path, patient,\n","                                          \"quarter_{}mm\".format(args.mm))\n","        patient_target_path = os.path.join(args.data_path, patient,\n","                                           \"full_{}mm\".format(args.mm))\n","\n","        for path_ in [patient_input_path, patient_target_path]:\n","            full_pixels = get_pixels_hu(load_scan(path_))\n","            for pi in range(len(full_pixels)):\n","                io = 'input' if 'quarter' in path_ else 'target'\n","                f = normalize_(full_pixels[pi], args.norm_range_min, args.norm_range_max)\n","                f_name = '{}_{}_{}.npy'.format(patient, pi, io)\n","                np.save(os.path.join(args.save_path, f_name), f)\n","\n","        printProgressBar(p_ind, len(patients_list),\n","                         prefix=\"save image ..\",\n","                         suffix='Complete', length=25)\n","        print(' ')"],"metadata":{"id":"KMryXodeSsl1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_scan(path):\n","    # referred from https://www.kaggle.com/gzuidhof/full-preprocessing-tutorial\n","    slices = [pydicom.read_file(os.path.join(path, s)) for s in os.listdir(path)]\n","    slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n","    try:\n","        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n","    except:\n","        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n","    for s in slices:\n","        s.SliceThickness = slice_thickness\n","    return slices\n","\n","\n","def get_pixels_hu(slices):\n","    # referred from https://www.kaggle.com/gzuidhof/full-preprocessing-tutorial\n","    image = np.stack([s.pixel_array for s in slices])\n","    image = image.astype(np.int16)\n","    image[image == -2000] = 0\n","    for slice_number in range(len(slices)):\n","        intercept = slices[slice_number].RescaleIntercept\n","        slope = slices[slice_number].RescaleSlope\n","        if slope != 1:\n","            image[slice_number] = slope * image[slice_number].astype(np.float64)\n","            image[slice_number] = image[slice_number].astype(np.int16)\n","        image[slice_number] += np.int16(intercept)\n","    return np.array(image, dtype=np.int16)\n","\n","\n","def normalize_(image, MIN_B=-1024.0, MAX_B=3072.0):\n","   image = (image - MIN_B) / (MAX_B - MIN_B)\n","   return image\n","\n","\n","def printProgressBar(iteration, total, prefix='', suffix='', decimals=1, length=100, fill=' '):\n","    # referred from https://gist.github.com/snakers4/91fa21b9dda9d055a02ecd23f24fbc3d\n","    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n","    filledLength = int(length * iteration // total)\n","    bar = fill * filledLength + '=' * (length - filledLength)\n","    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end='\\r')\n","    if iteration == total:\n","        print()\n","\n","\n","if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser()\n","\n","    parser.add_argument('--data_path', type=str, default='./AAPM-Mayo-CT-Challenge/')\n","    parser.add_argument('--save_path', type=str, default='./npy_img/')\n","\n","    parser.add_argument('--test_patient', type=str, default='L506')\n","    parser.add_argument('--mm', type=int, default=3)\n","    parser.add_argument('--norm_range_min', type=float, default=-1024.0)\n","    parser.add_argument('--norm_range_max', type=float, default=3072.0)\n","\n","    args = parser.parse_args()\n","    save_dataset(args)"],"metadata":{"id":"FiVqQOkUTl0m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["model training dan testing"],"metadata":{"id":"TYe7vBmA9gii"}},{"cell_type":"code","source":["import os\n","import argparse\n","from torch.backends import cudnn\n","from loader import get_loader\n","from solver import solver \n","\n","\n","import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '2,3'  ## 1/2 ,multi GPU"],"metadata":{"id":"eVYXbVReG9sK","executionInfo":{"status":"ok","timestamp":1672405292191,"user_tz":-420,"elapsed":13,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def main(args):\n","    cudnn.benchmark = True\n","\n","    if not os.path.exists(args.save_path):\n","        os.makedirs(args.save_path)\n","        print('Create path : {}'.format(args.save_path))"],"metadata":{"id":"dBjMq7KgCXYi","executionInfo":{"status":"ok","timestamp":1672405292192,"user_tz":-420,"elapsed":13,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["    if args.result_fig:\n","        fig_path = os.path.join(args.save_path, 'fig')\n","        if not os.path.exists(fig_path):\n","            os.makedirs(fig_path)\n","            print('Create path : {}'.format(fig_path))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"9e_aUtvAsdac","executionInfo":{"status":"error","timestamp":1672405292192,"user_tz":-420,"elapsed":13,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}},"outputId":"70d47f8a-337b-46d8-b15a-53287e21af3e"},"execution_count":26,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-9c37a06a2c20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_fig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mfig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fig'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Create path : {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"]}]},{"cell_type":"code","source":["    data_loader = get_loader(mode=args.mode,\n","                             load_mode=args.load_mode,\n","                             saved_path=args.saved_path,\n","                             test_patient=args.test_patient,\n","                             patch_n=(args.patch_n if args.mode=='train' else None),\n","                             patch_size=(args.patch_size if args.mode=='train' else None),\n","                             transform=args.transform,\n","                             batch_size=(args.batch_size if args.mode=='train' else 1),\n","                             shuffle=(True if args.mode=='train' else False),\n","                             num_workers=args.num_workers)\n","\n","    solver = Solver(args, data_loader)\n","    if args.mode == 'train':\n","        solver.train()\n","    elif args.mode == 'test':\n","        solver.test()\n","\n","\n","if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser()\n","\n","    parser.add_argument('--mode', type=str, default='train')\n","    parser.add_argument('--load_mode', type=int, default=0)\n","    parser.add_argument('--data_path', type=str, default='./AAPM-Mayo-CT-Challenge/')\n","    parser.add_argument('--saved_path', type=str, default='../aapm_all_npy_3mm/')   ##aapm_all_npy_3mm\n","    parser.add_argument('--save_path', type=str, default='save/')\n","    parser.add_argument('--test_patient', type=str, default='L506')\n","    parser.add_argument('--result_fig', type=bool, default=True)\n","\n","    parser.add_argument('--norm_range_min', type=float, default=-1024.0)\n","    parser.add_argument('--norm_range_max', type=float, default=3072.0)\n","    parser.add_argument('--trunc_min', type=float, default=-160.0)\n","    parser.add_argument('--trunc_max', type=float, default=240.0)\n","\n","    parser.add_argument('--transform', type=bool, default=False)\n","    # if patch training, batch size is (--patch_n * --batch_size)\n","    parser.add_argument('--patch_n', type=int, default=4)   ## 10\n","    parser.add_argument('--patch_size', type=int, default=64)    ## 64\n","    parser.add_argument('--batch_size', type=int, default=16)   ## batch size has to be very small if size=512,16\n","\n","    parser.add_argument('--num_epochs', type=int, default=4000)  ## 200 or 2000\n","    parser.add_argument('--print_iters', type=int, default=20)\n","    parser.add_argument('--decay_iters', type=int, default=8000)  ## original 3000 then 8000\n","    parser.add_argument('--save_iters', type=int, default=1500)  ## the iterats~epochs*10 useless for now\n","    parser.add_argument('--test_iters', type=int, default=135864)\n","\n","    parser.add_argument('--lr', type=float, default=1e-5)   \n","\n","    parser.add_argument('--device', type=str)  ##, default=[2,3]\n","    parser.add_argument('--num_workers', type=int, default=7)\n","    parser.add_argument('--multi_gpu', type=bool, default=True) ## 2/2 ,multi GPU\n","\n","    args = parser.parse_args()\n","    main(args)"],"metadata":{"id":"r3bfNZ06EkP8","executionInfo":{"status":"aborted","timestamp":1672405292193,"user_tz":-420,"elapsed":13,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["data di augmentasi"],"metadata":{"id":"XoyldyIWFZ2I"}},{"cell_type":"code","source":["import math\n","import torch\n","import torch.nn as nn\n","import numpy as np"],"metadata":{"id":"nm7GCm3pQpfw","executionInfo":{"status":"ok","timestamp":1672405760339,"user_tz":-420,"elapsed":345,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":[" from skimage.metrics import peak_signal_noise_ratio\n"," \n"," def weights_init_kaiming(m):\n","     classname = m.__class__.__name__\n","     if classname.find('Conv') != -1:\n","         nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n","     elif classname.find('Linear') != -1:\n","         nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n","     elif classname.find('BatchNorm') != -1:\n","         # nn.init.uniform(m.weight.data, 1.0, 0.02)\n","         m.weight.data.normal_(mean=0, std=math.sqrt(2./9./64.)).clamp_(-0.025,0.025)\n","         nn.init.constant(m.bias.data, 0.0)\n"," \n"," def batch_PSNR(img, imclean, data_range):\n","     Img = img.data.cpu().numpy().astype(np.float32)\n","     Iclean = imclean.data.cpu().numpy().astype(np.float32)\n","     PSNR = 0\n","     for i in range(Img.shape[0]):\n","         PSNR += compare_psnr(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n","     return (PSNR/Img.shape[0])"],"metadata":{"id":"KgVFuT7Dm-n3","executionInfo":{"status":"aborted","timestamp":1672405292194,"user_tz":-420,"elapsed":13,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def data_augmentation(image, mode):\n","    #out = np.transpose(image, (1,2,0))\n","    out = image\n","    if mode == 0:\n","        # original\n","        out = out\n","    elif mode == 1:\n","        # flip up and down\n","        out = np.flipud(out)\n","    elif mode == 2:\n","        # rotate counterwise 90 degree\n","        out = np.rot90(out)\n","    elif mode == 3:\n","        # rotate 90 degree and flip up and down\n","        out = np.rot90(out)\n","        out = np.flipud(out)\n","    elif mode == 4:\n","        # rotate 180 degree\n","        out = np.rot90(out, k=2)\n","    elif mode == 5:\n","        # rotate 180 degree and flip\n","        out = np.rot90(out, k=2)\n","        out = np.flipud(out)\n","    elif mode == 6:\n","        # rotate 270 degree\n","        out = np.rot90(out, k=3)\n","    elif mode == 7:\n","        # rotate 270 degree and flip\n","        out = np.rot90(out, k=3)\n","        out = np.flipud(out)\n","    #return np.transpose(out, (2,0,1))\n","    return out"],"metadata":{"id":"6ghf8p-k5bgF","executionInfo":{"status":"aborted","timestamp":1672405292194,"user_tz":-420,"elapsed":13,"user":{"displayName":"Anditto Waskitoputra","userId":"12545547817689174308"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tokenisasi dan transformer"],"metadata":{"id":"jLX6zVjSPPWQ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from einops import rearrange\n","\n","from timm.models.helpers import load_pretrained\n","from timm.models.registry import register_model\n","from timm.models.layers import trunc_normal_\n","import numpy as np\n","from token_transformer import Token_transformer    \n","from token_performer import Token_performer\n","from T2T_transformer_block import Block, get_sinusoid_encoding"],"metadata":{"id":"wP6fVlz7Ro6G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MultiHeadDense(nn.Module):\n","    def __init__(self, in_ch, out_ch):\n","        super(MultiHeadDense, self).__init__()\n","        self.weight = nn.Parameter(torch.Tensor(in_ch, out_ch))\n","    \n","    def forward(self, x):\n","        # x:[b, h*w, d]\n","        # x = torch.bmm(x, self.weight)\n","        x = F.linear(x, self.weight)\n","        return x"],"metadata":{"id":"ga8UZ9m-R0_1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class T2T_module(nn.Module):\n","    \"\"\"\n","    CTformer encoding module\n","    \"\"\"\n","    def __init__(self, img_size=64, tokens_type='performer', in_chans=1, embed_dim=256, token_dim=64, kernel=32, stride=32):\n","        super().__init__()\n","\n","        if tokens_type == 'transformer':\n","            print('adopt transformer encoder for tokens-to-token')\n","            self.soft_split0 = nn.Unfold(kernel_size=(7, 7), stride=(2, 2))\n","            self.soft_split1 = nn.Unfold(kernel_size=(3, 3), stride=(1, 1),dilation=(2,2))\n","            self.soft_split2 = nn.Unfold(kernel_size=(3, 3), stride=(1, 1))\n","\n","            self.attention1 = Token_transformer(dim=in_chans*7*7, in_dim=token_dim, num_heads=1, mlp_ratio=1.0)\n","            self.attention2 = Token_transformer(dim=token_dim*3*3, in_dim=token_dim, num_heads=1, mlp_ratio=1.0)\n","            self.project = nn.Linear(token_dim * 3 * 3, embed_dim)\n","\n","        elif tokens_type == 'performer':\n","            #print('adopt performer encoder for tokens-to-token')\n","            self.soft_split0 = nn.Unfold(kernel_size=(7, 7), stride=(2, 2))\n","            self.soft_split1 = nn.Unfold(kernel_size=(3, 3), stride=(1, 1),dilation=(2,2))\n","            self.soft_split2 = nn.Unfold(kernel_size=(3, 3), stride=(1, 1))\n","\n","            self.attention1 = Token_performer(dim=in_chans*7*7, in_dim=token_dim, kernel_ratio=0.5)\n","            self.attention2 = Token_performer(dim=token_dim*3*3, in_dim=token_dim, kernel_ratio=0.5)\n","            self.project = nn.Linear(token_dim * 3 * 3, embed_dim)\n","        #self.num_patches = (img_size // (1 * 2 * 2)) * (img_size // (1 * 2 * 2))  # there are 3 sfot split, stride are 4,2,2 seperately\n","        self.num_patches = 529   ## calculate myself\n","        \n","    def forward(self, x):\n","        \n","        # Tokenization\n","        x = self.soft_split0(x)   ## [1, 128, 64, 128])\n","        \n","        # CTformer module A\n","        x = self.attention1(x.transpose(1, 2))\n","        res_11 = x\n","        B, new_HW, C = x.shape\n","        x = x.transpose(1,2).reshape(B, C, int(np.sqrt(new_HW)), int(np.sqrt(new_HW)))\n","        x = torch.roll(x, shifts=(2, 2), dims=(2, 3))  ##  shift some position\n","        x = self.soft_split1(x)\n","        \n","        # CTformer module B\n","        x = self.attention2(x.transpose(1, 2))\n","        res_22 = x\n","        B, new_HW, C = x.shape\n","        x = x.transpose(1, 2).reshape(B, C, int(np.sqrt(new_HW)), int(np.sqrt(new_HW)))\n","        x = torch.roll(x, shifts=(2, 2), dims=(2, 3))  ## shift back position\n","        x = self.soft_split2(x)\n","        \n","        \n","        x = self.project(x.transpose(1, 2))  ## no projection\n","        return x,res_11,res_22 #,res0,res2"],"metadata":{"id":"jVYuS9hNWPlG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Token_back_Image(nn.Module):\n","    \"\"\"\n","    CTformer decoding module\n","    \"\"\"\n","    def __init__(self, img_size=64, tokens_type='performer', in_chans=1, embed_dim=256, token_dim=64, kernel=32, stride=32):\n","        super().__init__()\n","\n","        if tokens_type == 'transformer':\n","            print('adopt transformer encoder for tokens-to-token')\n","            self.soft_split0 = nn.Fold((64,64),kernel_size=(7, 7), stride=(2, 2))\n","            self.soft_split1 = nn.Fold((29,29),kernel_size=(3, 3), stride=(1, 1),dilation=(2,2))\n","            self.soft_split2 = nn.Fold((25,25),kernel_size=(3, 3), stride=(1, 1))\n","\n","            self.attention1 = Token_transformer(dim=token_dim, in_dim=in_chans*7*7, num_heads=1, mlp_ratio=1.0)\n","            self.attention2 = Token_transformer(dim=token_dim, in_dim=token_dim*3*3, num_heads=1, mlp_ratio=1.0)\n","            self.project = nn.Linear(embed_dim,token_dim * 3 * 3)\n","        elif tokens_type == 'performer':\n","            #print('adopt performer encoder for tokens-to-token')\n","            self.soft_split0 = nn.Fold((64,64),kernel_size=(7, 7), stride=(2, 2))\n","            self.soft_split1 = nn.Fold((29,29),kernel_size=(3, 3), stride=(1, 1),dilation=(2,2))\n","            self.soft_split2 = nn.Fold((25,25),kernel_size=(3, 3), stride=(1, 1))\n","\n","            self.attention1 = Token_performer(dim=token_dim, in_dim=in_chans*7*7, kernel_ratio=0.5)\n","            self.attention2 = Token_performer(dim=token_dim, in_dim=token_dim*3*3, kernel_ratio=0.5)\n","            self.project = nn.Linear(embed_dim,token_dim * 3 * 3)\n","\n","        self.num_patches = (img_size // (1 * 2 * 2)) * (img_size // (1 * 2 * 2))  # there are 3 sfot split, stride are 4,2,2 seperately\n","\n","    def forward(self, x, res_11,res_22):    \n","        x = self.project(x).transpose(1, 2) \n","\n","        # CTformer module C\n","        x = self.soft_split2(x)\n","        x = torch.roll(x, shifts=(-2, -2), dims=(-1, -2))\n","        x = rearrange(x,'b c h w -> b c (h w)').transpose(1,2)\n","        x = x + res_22\n","        x = self.attention2(x).transpose(1, 2)\n","        \n","        # CTformer module D\n","        x = self.soft_split1(x)\n","        x = torch.roll(x, shifts=(-2, -2), dims=(-1, -2))\n","        x = rearrange(x,'b c h w -> b c (h w)').transpose(1,2)\n","        x = x + res_11\n","        x = self.attention1(x).transpose(1, 2)\n","        \n","        # Detokenization\n","        x = self.soft_split0(x) \n","\n","        return x\n"],"metadata":{"id":"MQSH3FpdR7AG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CTformer(nn.Module):\n","    def __init__(self, img_size=512, tokens_type='convolution', in_chans=1, num_classes=1000, embed_dim=768, depth=12,  ## transformer depth 12\n","                 num_heads=12, kernel=32, stride=32, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop_rate=0.1, attn_drop_rate=0.1,\n","                 drop_path_rate=0.1, norm_layer=nn.LayerNorm, token_dim=1024):\n","        super().__init__()\n","        self.num_classes = num_classes\n","        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n","\n","        self.tokens_to_token = T2T_module(    ## use module 2\n","                img_size=img_size, tokens_type=tokens_type, in_chans=in_chans, embed_dim=embed_dim, token_dim=token_dim,kernel=kernel, stride=stride)\n","        num_patches = self.tokens_to_token.num_patches\n","\n","        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n","        self.pos_embed = nn.Parameter(data=get_sinusoid_encoding(n_position=num_patches, d_hid=embed_dim), requires_grad=False)\n","        self.pos_drop = nn.Dropout(p=drop_rate)\n","\n","        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n","        self.blocks = nn.ModuleList([\n","            Block(\n","                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n","                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer)\n","            for i in range(depth)])\n","        self.norm = norm_layer(embed_dim)\n","\n","        # CTformer decoder\n","        self.dconv1 = Token_back_Image(img_size=img_size, tokens_type=tokens_type, in_chans=in_chans, embed_dim=embed_dim, token_dim=token_dim, kernel=kernel, stride=stride)\n","        self.head = nn.Linear(embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n","\n","        trunc_normal_(self.cls_token, std=.02)\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, m):\n","        if isinstance(m, nn.Linear):\n","            trunc_normal_(m.weight, std=.02)\n","            if isinstance(m, nn.Linear) and m.bias is not None:\n","                nn.init.constant_(m.bias, 0)\n","        elif isinstance(m, nn.LayerNorm):\n","            nn.init.constant_(m.bias, 0)\n","            nn.init.constant_(m.weight, 1.0)\n","\n","    @torch.jit.ignore\n","    def no_weight_decay(self):\n","        return {'cls_token'}\n","\n","    def get_classifier(self):\n","        return self.head\n","\n","    def reset_classifier(self, num_classes, global_pool=''):\n","        self.num_classes = num_classes\n","        self.head = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n","\n","    def forward(self, x):\n","        res1 = x\n","        x, res_11, res_22 = self.tokens_to_token(x)\n","        x = x + self.pos_embed\n","        x = self.pos_drop(x)\n","        \n","        i = 0\n","        for blk in self.blocks: ## only one intermediate transformer block\n","            i += 1\n","            x = blk(x)\n","\n","        x = self.norm(x) #+ res_0   ## do not use 0,2,4\n","        out = res1 - self.dconv1(x,res_11,res_22)\n","        return out"],"metadata":{"id":"6EHupdIWWgf0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["token token dilation block"],"metadata":{"id":"J3Fyj8oPYhLc"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","from timm.models.layers import DropPath"],"metadata":{"id":"naXuKgCyYKjd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def intra_att_f(querys,keys,values):  ## works\n","\n","    len = querys.shape[-1]\n","    att = torch.zeros(querys.shape)\n","    for q in range(querys.shape[0]):\n","      tmp_q = torch.zeros(len, len)\n","      for k in keys:\n","        tmp = querys[q].reshape(len,1) @ k.reshape(1,len) * (torch.ones(len, len) - torch.eye(len, len))\n","        tmp_q += tmp\n","        #a = querys[q].T @ k\n","      att[q] = torch.sum(tmp_q, dim=0).reshape((1,-1))\n","\n","    #att = softmax(att, dim=0)\n","    return values*att\n","\n","    class Mlp(nn.Module):\n","    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n","        super().__init__()\n","        out_features = out_features or in_features\n","        hidden_features = hidden_features or in_features\n","        self.fc1 = nn.Linear(in_features, hidden_features)\n","        self.act = act_layer()\n","        self.fc2 = nn.Linear(hidden_features, out_features)\n","        self.drop = nn.Dropout(drop)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.act(x)\n","        x = self.drop(x)\n","        x = self.fc2(x)\n","        x = self.drop(x)\n","        return x"],"metadata":{"id":"OmD4fRKxY1QE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class intra_att(nn.Module):    ## define a new attention\n","  def __init__(self,dim=64):\n","    super().__init__()\n","    self.qkv = nn.Linear(dim, dim * 3)\n","  def forward(self,x):\n","    N, C = x.shape\n","    qkv = self.qkv(x)\n","    print(qkv.shape)\n","    querys, keys, values = qkv[0], qkv[1], qkv[2]\n","\n","    len = querys.shape[-1]\n","    att = torch.zeros(querys.shape)\n","    for q in range(querys.shape[0]):\n","      tmp_q = torch.zeros(len, len)\n","      for k in keys:\n","        tmp = querys[q].reshape(len,1) @ k.reshape(1,len) * (torch.ones(len, len) - torch.eye(len, len))\n","        tmp_q += tmp\n","        #a = querys[q].T @ k\n","      att[q] = torch.sum(tmp_q, dim=0).reshape((1,-1))\n","\n","    #att = softmax(att, dim=0)\n","    return values*att"],"metadata":{"id":"JtdGEJraZNf9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Block(nn.Module):\n","\n","    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n","                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n","        super().__init__()\n","        self.norm1 = norm_layer(dim)\n","        self.attn = Attention(\n","            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n","        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n","        self.norm2 = norm_layer(dim)\n","        mlp_hidden_dim = int(dim * mlp_ratio)\n","        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n","\n","    def forward(self, x):\n","        x = x + self.drop_path(self.attn(self.norm1(x)))\n","        x = x + self.drop_path(self.mlp(self.norm2(x)))\n","        return x\n","\n","\n","def get_sinusoid_encoding(n_position, d_hid):\n","    ''' Sinusoid position encoding table '''\n","\n","    def get_position_angle_vec(position):\n","        return [position / np.power(10000, 2 * (hid_j // 2) / d_hid) for hid_j in range(d_hid)]\n","\n","    sinusoid_table = np.array([get_position_angle_vec(pos_i) for pos_i in range(n_position)])\n","    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n","    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n","\n","    return torch.FloatTensor(sinusoid_table).unsqueeze(0)"],"metadata":{"id":"kFOP5-nWZSj9"},"execution_count":null,"outputs":[]}]}